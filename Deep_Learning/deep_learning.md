# Deep Learning
# Implizite Merkmalsextraktion durch neuronale Netze
Einen Teilbereich der kÃ¼nstlicher Intelligenz stellt das maschinelle Lernen dar. Hier erfolgt eine Mustererkennung nicht nach vorher festgelegten Regeln, sondern anhand intrinsischer Merkmale der Datenpunkte. Diese kÃ¶nnen im Fall des unÃ¼berwachten Lernens mittels einer definierten Ã„hnlichkeitsmetrik, wie z.B. des geometrischen Abstands, gruppiert werden. Beim Ã¼berwachten Lernen findet in einer vorhergehenden Datenanalyse eine Klassifizierung der in dieser Phase vorkommenden Merkmale statt. AnschlieÃŸend werden diese Klassen separiert und die daraus abgeleiteten Klassengrenzen fÃ¼r die Klassifizierung von Daten auÃŸerhalb der Trainingsphase verwendet.
Zur sinnvollen Trennung der Daten muss oft im Vorfeld eine Merkmalsextraktion und -selektion stattfinden, dies bedeutet, genau die Merkmale zu finden, die den Datensatz noch gut genug beschreiben und sinnvoll trennen. Merkmale, die eine geringe ReprÃ¤sentation besitzen werden verworfen. Eine Anwendung des klassischen maschinellen Lernens geht dadurch bei multivarianten Daten oft mit einer manuellen Vorarbeit einher. Auf diese manuelle Merkmalsextraktion kann bei der Anwendung des tiefen Lernens verzichtet werden. Die beim tiefen Lernen angewandten Topologien neuronaler Netze ermÃ¶glichen eine implizite Merkmalsextraktion durch automatische Anpassung ihrer Parameter aufgrund von Trainingsdaten.
  * Mittels tiefer neuronaler Netze kÃ¶nnen Merkmale ohne vorherige Featureextraktion herausgebildet werden
  
## Neuronale Netze
  
### McCulloch/Pitts Zelle
Der Beginn der Entwicklung kÃ¼nstlicher neuronaler Netze wird oft auf das 1943 von Warren McCulloch und Walter Pitts vorgestellte â€kÃ¼nstliche Neuronâ€œ datiert. Inspiriert von der damaligen Grundlagenforschung zu biologischen Neuronen stellt das â€kÃ¼nstliche Neuronâ€œ ein einfaches Modell dar, das die Signalweiterleitung im Gehirn simulieren soll. Dieses Neuron besteht aus mehreren Eingangsleitungen und einer Ausgangsleitung, die jeweils binÃ¤re Signale verarbeiten oder ausgeben kÃ¶nnen. Die Eingangsleitungen kÃ¶nnen dabei das Attribut â€hemmendâ€œ oder â€bestÃ¤rkendâ€œ besitzen. Ist mindestens eine hemmende Eingangsleitung aktiv, wird der Ausgang des Neurons inaktiv geschaltet. Sind eine vorgegebene Menge an bestÃ¤rkenden Eingangsleitungen aktiv, schaltet das Neuron den Ausgang aktiv. Durch Vernetzung mehrerer derartiger kÃ¼nstlicher Neuronen ist die Berechnung komplexer logischer VerknÃ¼pfungen mÃ¶glich. Die Netze werden dann fÃ¼r die jeweilige Aufgabe im Vornherein parametriert, indem die hemmenden und bestÃ¤rkenden Leitungen und die Schaltschwellen vorgegeben werden

![](Images/mcculloch.png "McCulloch Pitts")
  
### Multilayer Perzeptron
Im Jahre 1957 stellte Frank Rosenblatt das sogenannte Perzeptron als ein erweitertes Modell eines kÃ¼nstlichen Neurons vor. Die Signale sind hier nicht mehr binÃ¤r, sondern kÃ¶nnen Zahlenwerte annehmen. Jede Eingangsleitung besitzt eine Gewichtung mit der die einzelnen Signalwerte multipliziert werden. Die Summe dieser gewichteten Werte wird als Eingabewert einer sogenannten Aktivierungsfunktion verwendet. Der Ausgabewert dieser Funktion ist der des Perzeptrons. Als Aktivierungsfunktion wird zum Beispiel die Heaviside-Funktion verwendet.
  
â„ğ‘’ğ‘ğ‘£ğ‘–ğ‘ ğ‘–ğ‘‘ğ‘’(ğ‘§)={
    0 ğ‘¤ğ‘’ğ‘›ğ‘› ğ‘§<0 
    1 ğ‘¤ğ‘’ğ‘›ğ‘› ğ‘§â‰¥0
}
  
Durch Hintereinanderschaltung mehrerer paralleler Perzeptronen wurde die Basis moderner kÃ¼nstlicher neuronaler Netze gelegt. Die Topologie derartiger Netze besteht aus einer Eingabeschicht, die jedes Eingangssignal an jedes in der dahinterliegenden Schicht liegende Neuron weiterleitet. Auf diese Schicht kÃ¶nnen dann beliebig viele weitere Schichten gestapelt werden. Die letzte dieser Schichten wird als Ausgabeschicht bezeichnet, die zwischen dieser und der Eingabeschicht liegenden als verborgende Schichten. Liegt ein Netz mit insgesamt drei Schichten vor, wird dieses Netz als Multilayer Perzeptron bezeichnet. Erst 1986 wurde mit dem Backpropagation-Algorithmus und der Ersetzung der Heaviside-Aktivierungsfunktion mit einer stetig differenzierbaren Funktion die MÃ¶glichkeit gegeben neuronale Netze aufgrund von Daten zu trainieren
  
### Tiefe neuronale Netze
Mit der Verwendung mehrerer verborgener Schichten nimmt die AbstraktionsfÃ¤higkeit des neuronalen Netzes zu. Dies liegt an der mit der Schichttiefe exponentiell steigenden Anzahl von Parametern, u.a. der Kantengewichte. Mittels dieser tiefen Schichten, bei denen sich die Anzahl der Neuronen pro Schicht fÃ¼r gewÃ¶hnlich verringern, sind komplexe Mustererkennungen, wie z.B. von Gesichtern mÃ¶glich. Allerdings geht dieser Anstieg der LeistungsfÃ¤higkeit mit Problemen einher. Zum einen tritt beim Training mittels Backpropagation-Verfahren das Problem des explodierenden oder verschwindenden Gradienten auf. Wird ein Fehler von der Ausgabeschicht zur Eingabeschicht zurÃ¼ckpropagiert, wird dieser immer kleiner. Im schlechtesten Fall werden die untersten Schichten gar nicht trainiert. Weiter besteht das Problem der Ãœberanpassung. Je mehr Parameter das neuronale Netz besitzt, desto eher neigt es dazu, den Trainingsdatensatz als solches zu reprÃ¤sentieren und nicht die Muster der Daten des Trainingssatzes zu extrahieren. Um einer Ãœberanpassung zu entgehen, muss die Menge an Trainingsdaten grÃ¶ÃŸer werden. Damit steigt dann auch die Dauer des Trainings
  
### Rekurrente neuronale Netze
Bei den bislang vorgestellten Netztopologien handelt es sich um Feed-Forward-Netze. Ein Eingabevektor wird hier durch das Netz bis zur Ausgabeschicht propagiert. Dies ist fÃ¼r statische Daten wie Bilder sinnvoll, es ermÃ¶glicht allerdings keine EinprÃ¤gung zeitlicher Muster. Bei rekurrenten Netzen wird diese AbhÃ¤ngigkeit zeitlicher Muster durch die EinfÃ¼hrung von rÃ¼ckwÃ¤rts gerichteten Verbindungen innerhalb des Netzes erreicht. Im einfachsten Fall besteht ein derartiges Netz aus einem Neuron, das zum nÃ¤chsten Zeitpunkt t zusÃ¤tzlich zum neuen Eingabewert seine Ausgabe vom letzten Zeitpunkt t-1 erhÃ¤lt. Werden mehrere derartige Neuronen in einer Schicht kombiniert, erhalten diese neben einem neuen Eingabevektor die Ausgabe des letzten AusfÃ¼hrungszeitpunktes. Nachteil dieses einfachen Netzes ist, dass zeitliche Eingaben zu frÃ¼hen Zeitpunkten aufgrund der andauernden Transformation mittels neuer Daten langsam â€verblassenâ€œ. Die Netztopologie besitzt damit kein LangzeitgedÃ¤chtnis. Komplexere Zellen, wie die LSTM-Zelle oder GRU-Zelle verringern dieses Problem. Die Long-Short-Term Memory-Zelle (LSTM) besitzt so zwei Zustandsvektoren, von denen der eine die kurzfristigen Merkmale und der andere die lÃ¤ngerfristigen Merkmale abspeichern soll